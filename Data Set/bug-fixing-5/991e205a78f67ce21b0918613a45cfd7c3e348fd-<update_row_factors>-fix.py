def update_row_factors(self, sp_input=None, transpose_input=False):
    'Updates the row factors.\n\n    Args:\n      sp_input: A SparseTensor representing a subset of rows of the full input\n        in any order. Please note that this SparseTensor must retain the\n        indexing as the original input.\n      transpose_input: If true, the input will be logically transposed and the\n        rows corresponding to the transposed input are updated.\n\n    Returns:\n      A tuple consisting of the following elements:\n      new_values: New values for the row factors.\n      update_op: An op that assigns the newly computed values to the row\n        factors.\n      unregularized_loss: A tensor (scalar) that contains the normalized\n        minibatch loss corresponding to sp_input, without the regularization\n        term. If sp_input contains the rows \\\\({A_{i, :}, i \\in I}\\\\), and the\n        input matrix A has n total rows, then the unregularized loss is:\n        \\\\(\\|\\sqrt W_I \\odot (A_I - U_I V^T)\\|_F^2 * n / |I|\\\\)\n        The total loss is unregularized_loss + regularization.\n      regularization: A tensor (scalar) that contains the normalized\n        regularization term for the minibatch loss corresponding to sp_input.\n        If sp_input contains the rows \\\\({A_{i, :}, i \\in I}\\\\), and the input\n        matrix A has n total rows, then the regularization term is:\n        \\\\(\\lambda \\|U_I\\|_F^2) * n / |I| + \\lambda \\|V\\|_F^2\\\\).\n      sum_weights: The sum of the weights W_I corresponding to sp_input,\n        normalized by a factor of \\\\(n / |I|\\\\). The root weighted squared\n        error is: \\sqrt(unregularized_loss / sum_weights).\n    '
    return self._process_input_helper(True, sp_input=sp_input, transpose_input=transpose_input)