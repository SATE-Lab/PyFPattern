def memory_usage(self, index=True, deep=False):
    "\n        Return the memory usage of each column in bytes.\n\n        The memory usage can optionally include the contribution of\n        the index and elements of `object` dtype.\n\n        This value is displayed in `DataFrame.info` by default. This can be\n        suppressed by setting ``pandas.options.display.memory_usage`` to False.\n\n        Parameters\n        ----------\n        index : bool, default True\n            Specifies whether to include the memory usage of the DataFrame's\n            index in returned Series. If ``index=True`` the memory usage of the\n            index the first item in the output.\n        deep : bool, default False\n            If True, introspect the data deeply by interrogating\n            `object` dtypes for system-level memory consumption, and include\n            it in the returned values.\n\n        Returns\n        -------\n        sizes : Series\n            A Series whose index is the original column names and whose values\n            is the memory usage of each column in bytes.\n\n        See Also\n        --------\n        numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n            ndarray.\n        Series.memory_usage : Bytes consumed by a Series.\n        pandas.Categorical : Memory-efficient array for string values with\n            many repeated values.\n        DataFrame.info : Concise summary of a DataFrame.\n\n        Examples\n        --------\n        >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n        >>> data = dict([(t, np.ones(shape=5000).astype(t))\n        ...              for t in dtypes])\n        >>> df = pd.DataFrame(data)\n        >>> df.head()\n           int64  float64  complex128 object  bool\n        0      1      1.0      (1+0j)      1  True\n        1      1      1.0      (1+0j)      1  True\n        2      1      1.0      (1+0j)      1  True\n        3      1      1.0      (1+0j)      1  True\n        4      1      1.0      (1+0j)      1  True\n\n        >>> df.memory_usage()\n        Index            80\n        int64         40000\n        float64       40000\n        complex128    80000\n        object        40000\n        bool           5000\n        dtype: int64\n\n        >>> df.memory_usage(index=False)\n        int64         40000\n        float64       40000\n        complex128    80000\n        object        40000\n        bool           5000\n        dtype: int64\n\n        The memory footprint of `object` dtype columns is ignored by default:\n\n        >>> df.memory_usage(deep=True)\n        Index             80\n        int64          40000\n        float64        40000\n        complex128     80000\n        object        160000\n        bool            5000\n        dtype: int64\n\n        Use a Categorical for efficient storage of an object-dtype column with\n        many repeated values.\n\n        >>> df['object'].astype('category').memory_usage(deep=True)\n        5168\n        "
    result = Series([c.memory_usage(index=False, deep=deep) for (col, c) in self.iteritems()], index=self.columns)
    if index:
        result = Series(self.index.memory_usage(deep=deep), index=['Index']).append(result)
    return result