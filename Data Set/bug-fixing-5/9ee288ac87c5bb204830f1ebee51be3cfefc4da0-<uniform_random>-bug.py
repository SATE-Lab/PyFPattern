@templatedoc()
def uniform_random(shape, dtype='float32', min=(- 1.0), max=1.0, seed=0):
    '\n    This operator initializes a variable with random values sampled from a\n    uniform distribution. The random result is in set [min, max).\n\n    Examples:\n    ::\n    \n        Input:\n          shape = [1, 2]\n        \n        Output:\n          result=[[0.8505902, 0.8397286]]\n\n    Args:\n        shape (list|tuple|Variable): The shape of the output tensor, the data type of the integer is int,\n                                     and if the shape type is list or tuple, its elements can be an integer\n                                     or a tensor with the shape [1], the data type of the tensor is int64. \n                                     If the shape type is Variable,it ia a 1D tensor, the data type of the tensor is int64.\n        dtype(np.dtype|core.VarDesc.VarType|str, optional): The data type of the output tensor, such as float32, float64.\n                                                  Default: float32.\n        min (float, optional): Minimum value of uniform random, It\'s a closed interval. Default -1.0.\n        max (float, optional): Maximun value of uniform random, It\'s an open interval. Default 1.0.\n        seed (int, optional): Random seed used for generating samples. 0 means use a\n            seed generated by the system. Note that if seed is not 0, this\n            operator will always generate the same random numbers every time.\n            Default 0.\n\n    Returns: a Tensor with randomly initialized results whose data type is determined by the dtype parameter \n                and whose dimension is determined by the shape parameter.\n    Return type: Variable\n\n    Throw exception:\n        TypeError: The shape type should be list or tupple or variable.\n    \n    Examples:\n        .. code-block:: python\n\n            import paddle.fluid as fluid\n\n            # example 1:\n            # attr shape is a list which doesn\'t contain tensor Variable.\n            result_1 = fluid.layers.uniform_random(shape=[3, 4])\n\n            # example 2:\n            # attr shape is a list which contains tensor Variable.\n            dim_1 = fluid.layers.fill_constant([1],"int64",3)\n            result_2 = fluid.layers.uniform_random(shape=[dim_1, 5])\n\n            # example 3:\n            # attr shape is a Variable, the data type must be int64\n            var_shape = fluid.layers.data(name=\'var_shape\',shape=[2],append_batch_size=False)\n            result_3 = fluid.layers.uniform_random(var_shape)\n\n    '
    if (not isinstance(shape, (list, tuple, Variable))):
        raise TypeError(('Input shape must be a python list,Variable or tuple. But received %s' % type(shape)))
    if (not isinstance(dtype, core.VarDesc.VarType)):
        dtype = convert_np_dtype_to_dtype_(dtype)
    if (convert_dtype(dtype) not in ['float32', 'float64']):
        raise TypeError(('The attribute dtype in uniform_random op must be float32 or float64, but received %s.' % convert_dtype(dtype)))

    def contain_var(one_list):
        for ele in one_list:
            if isinstance(ele, Variable):
                return True
        return False

    def get_new_shape_tensor(list_shape):
        new_shape_tensor = []
        for dim in list_shape:
            if isinstance(dim, Variable):
                dim.stop_gradient = True
                new_shape_tensor.append(dim)
            else:
                assert isinstance(dim, int)
                temp_out = helper.create_variable_for_type_inference('int64')
                fill_constant([1], 'int64', dim, force_cpu=True, out=temp_out)
                new_shape_tensor.append(temp_out)
        return new_shape_tensor

    def get_attr_shape(list_shape):
        unk_dim_idx = (- 1)
        attrs_shape = []
        for (dim_idx, dim_size) in enumerate(list_shape):
            if isinstance(dim_size, Variable):
                attrs_shape.append((- 1))
            else:
                attrs_shape.append(dim_size)
                assert (dim_size > 0), 'Each dimension size given in shape must not be negtive except one unknown dimension.'
        return attrs_shape
    helper = LayerHelper('uniform_random', **locals())
    inputs = dict()
    attrs = dict()
    if in_dygraph_mode():
        attrs = {
            'shape': shape,
        }
    elif isinstance(shape, Variable):
        shape.stop_gradient = True
        inputs['ShapeTensor'] = shape
    elif isinstance(shape, (list, tuple)):
        assert (len(shape) > 0), "The size of argument(shape) can't be zero."
        attrs['shape'] = get_attr_shape(shape)
        if contain_var(shape):
            inputs['ShapeTensorList'] = get_new_shape_tensor(shape)
    out = helper.create_variable_for_type_inference(dtype)
    helper.append_op(type='uniform_random', inputs=inputs, attrs=attrs, outputs={
        'Out': out,
    })
    return helper.append_activation(out)