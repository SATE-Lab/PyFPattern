def evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False):
    'Returns the loss value & metrics values for the model in test mode.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Input data. It could be:\n                - A Numpy array (or array-like), or a list of arrays\n                  (in case the model has multiple inputs).\n                - A dict mapping input names to the corresponding\n                  array/tensors, if the model has named inputs.\n                - A generator or `keras.utils.Sequence` returning\n                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n                - None (default) if feeding from framework-native\n                  tensors (e.g. TensorFlow data tensors).\n            y: Target data. Like the input data `x`,\n                it could be either Numpy array(s), framework-native tensor(s),\n                list of Numpy arrays (if the model has multiple outputs) or\n                None (default) if feeding from framework-native tensors\n                (e.g. TensorFlow data tensors).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                If `x` is a generator, or `keras.utils.Sequence` instance,\n                `y` should not be specified (since targets will be obtained\n                from `x`).\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` is your data is in the\n                form of symbolic tensors, generators, or\n                `keras.utils.Sequence` instances (since they generate batches).\n            verbose: 0 or 1. Verbosity mode.\n                0 = silent, 1 = progress bar.\n            sample_weight: Optional Numpy array of weights for\n                the test samples, used for weighting the loss function.\n                You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode="temporal"` in `compile()`.\n            steps: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during evaluation.\n                See [callbacks](/callbacks).\n            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n                input only. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Used for generator or `keras.utils.Sequence` input\n                only. Maximum number of processes to spin up when using\n                process-based threading. If unspecified, `workers` will default\n                to 1. If 0, will execute the generator on the main thread.\n            use_multiprocessing: Boolean. Used for generator or\n                `keras.utils.Sequence` input only. If `True`, use process-based\n                threading. If unspecified, `use_multiprocessing` will default to\n                `False`. Note that because this implementation relies on\n                multiprocessing, you should not pass non-picklable arguments to\n                the generator as they can\'t be passed easily to children processes.\n\n        # Raises\n            ValueError: in case of invalid arguments.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        '
    batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)
    if training_utils.is_generator_or_sequence(x):
        training_utils.check_generator_arguments(y, sample_weight)
        return self.evaluate_generator(x, steps=steps, verbose=verbose, callbacks=callbacks, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing)
    if ((x is None) and (y is None) and (steps is None)):
        raise ValueError('If evaluating from data tensors, you should specify the `steps` argument.')
    (x, y, sample_weights) = self._standardize_user_data(x, y, sample_weight=sample_weight, batch_size=batch_size)
    if self._uses_dynamic_learning_phase():
        ins = (((x + y) + sample_weights) + [0])
    else:
        ins = ((x + y) + sample_weights)
    self._make_test_function()
    f = self.test_function
    return training_arrays.test_loop(self, f, ins, batch_size=batch_size, verbose=verbose, steps=steps, callbacks=callbacks)