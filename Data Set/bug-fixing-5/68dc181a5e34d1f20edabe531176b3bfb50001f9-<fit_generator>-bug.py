@interfaces.legacy_generator_methods_support
def fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0):
    'Trains the model on data generated batch-by-batch by a Python generator\n        (or an instance of `Sequence`).\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        The use of `keras.utils.Sequence` guarantees the ordering\n        and guarantees the single use of every input per epoch when\n        using `use_multiprocessing=True`.\n\n        # Arguments\n            generator: A generator or an instance of `Sequence`\n                (`keras.utils.Sequence`) object in order to avoid\n                duplicate data when using multiprocessing.\n                The output of the generator must be either\n                - a tuple `(inputs, targets)`\n                - a tuple `(inputs, targets, sample_weights)`.\n                This tuple (a single output of the generator) makes a single\n                batch. Therefore, all arrays in this tuple must have the same\n                length (equal to the size of this batch). Different batches may\n                have different sizes. For example, the last batch of the epoch\n                is commonly smaller than the others, if the size of the dataset\n                is not divisible by the batch size.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Integer.\n                Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of samples of your dataset\n                divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(generator)` as a number of steps.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire data provided,\n                as defined by `steps_per_epoch`.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as "final epoch".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_data: This can be either\n                - a generator or a `Sequence` object for the validation data\n                - tuple `(x_val, y_val)`\n                - tuple `(x_val, y_val, val_sample_weights)`\n                on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n            validation_steps: Only relevant if `validation_data`\n                is a generator. Total number of steps (batches of samples)\n                to yield from `validation_data` generator before stopping\n                at the end of every epoch. It should typically\n                be equal to the number of samples of your\n                validation dataset divided by the batch size.\n                Optional for `Sequence`: if unspecified, will use\n                the `len(validation_data)` as a number of steps.\n            validation_freq: Only relevant if validation data is provided. Integer\n                or `collections.Container` instance (e.g. list, tuple, etc.). If an\n                integer, specifies how many training epochs to run before a new\n                validation run is performed, e.g. `validation_freq=2` runs\n                validation every 2 epochs. If a Container, specifies the epochs on\n                which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n                validation at the end of the 1st, 2nd, and 10th epochs.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only). This can be useful to tell the model to\n                "pay more attention" to samples\n                from an under-represented class.\n            max_queue_size: Integer. Maximum size for the generator queue.\n                If unspecified, `max_queue_size` will default to 10.\n            workers: Integer. Maximum number of processes to spin up\n                when using process-based threading.\n                If unspecified, `workers` will default to 1. If 0, will\n                execute the generator on the main thread.\n            use_multiprocessing: Boolean.\n                If `True`, use process-based threading.\n                If unspecified, `use_multiprocessing` will default to `False`.\n                Note that because this implementation\n                relies on multiprocessing,\n                you should not pass non-picklable arguments to the generator\n                as they can\'t be passed easily to children processes.\n            shuffle: Boolean. Whether to shuffle the order of the batches at\n                the beginning of each epoch. Only used with instances\n                of `Sequence` (`keras.utils.Sequence`).\n                Has no effect when `steps_per_epoch` is not `None`.\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            ValueError: In case the generator yields data in an invalid format.\n\n        # Example\n\n        ```python\n        def generate_arrays_from_file(path):\n            while True:\n                with open(path) as f:\n                    for line in f:\n                        # create numpy arrays of input data\n                        # and labels, from each line in the file\n                        x1, x2, y = process_line(line)\n                        yield ({\'input_1\': x1, \'input_2\': x2}, {\'output\': y})\n\n        model.fit_generator(generate_arrays_from_file(\'/my_file.txt\'),\n                            steps_per_epoch=10000, epochs=10)\n        ```\n        '
    return training_generator.fit_generator(self, generator, steps_per_epoch=steps_per_epoch, epochs=epochs, verbose=verbose, callbacks=callbacks, validation_data=validation_data, validation_steps=validation_steps, validation_freq=validation_freq, class_weight=class_weight, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing, shuffle=shuffle, initial_epoch=initial_epoch)