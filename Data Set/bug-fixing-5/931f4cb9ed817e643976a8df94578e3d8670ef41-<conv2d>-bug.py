@tf_export(v1=['nn.conv2d'])
def conv2d(input, filter=None, strides=None, padding=None, use_cudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None, filters=None):
    'Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n\n  Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n  and a filter / kernel tensor of shape\n  `[filter_height, filter_width, in_channels, out_channels]`, this op\n  performs the following:\n\n  1. Flattens the filter to a 2-D matrix with shape\n     `[filter_height * filter_width * in_channels, output_channels]`.\n  2. Extracts image patches from the input tensor to form a *virtual*\n     tensor of shape `[batch, out_height, out_width,\n     filter_height * filter_width * in_channels]`.\n  3. For each patch, right-multiplies the filter matrix and the image patch\n     vector.\n\n  In detail, with the default NHWC format,\n\n      output[b, i, j, k] =\n          sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]\n                          * filter[di, dj, q, k]\n\n  Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n  horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n\n  Args:\n    input: A `Tensor`. Must be one of the following types:\n      `half`, `bfloat16`, `float32`, `float64`.\n      A 4-D tensor. The dimension order is interpreted according to the value\n      of `data_format`, see below for details.\n    filter: A `Tensor`. Must have the same type as `input`.\n      A 4-D tensor of shape\n      `[filter_height, filter_width, in_channels, out_channels]`\n    strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n      stride of the sliding window for each dimension of `input`. If a single\n      value is given it is replicated in the `H` and `W` dimension. By default\n      the `N` and `C` dimensions are set to 1. The dimension order is determined\n      by the value of `data_format`, see below for details.\n    padding: Either the `string` `"SAME"` or `"VALID"` indicating the type of\n      padding algorithm to use, or a list indicating the explicit paddings at\n      the start and end of each dimension. When explicit padding is used and\n      data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,\n      pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n      and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],\n      [pad_top, pad_bottom], [pad_left, pad_right]]`.\n    use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n    data_format: An optional `string` from: `"NHWC", "NCHW"`.\n      Defaults to `"NHWC"`.\n      Specify the data format of the input and output data. With the\n      default format "NHWC", the data is stored in the order of:\n          [batch, height, width, channels].\n      Alternatively, the format could be "NCHW", the data storage order of:\n          [batch, channels, height, width].\n    dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n      defaults to 1. The dilation factor for each dimension of`input`. If a\n      single value is given it is replicated in the `H` and `W` dimension. By\n      default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n      will be k-1 skipped cells between each filter element on that dimension.\n      The dimension order is determined by the value of `data_format`, see above\n      for details. Dilations in the batch and depth dimensions if a 4-d tensor\n      must be 1.\n    name: A name for the operation (optional).\n    filters: Alias for filter.\n\n  Returns:\n    A `Tensor`. Has the same type as `input`.\n  '
    filter = deprecation.deprecated_argument_lookup('filters', filters, 'filter', filter)
    (padding, explicit_paddings) = _convert_padding(padding)
    if (data_format is None):
        data_format = 'NHWC'
    channel_index = (1 if data_format.startswith('NC') else 3)
    strides = _get_sequence(strides, 2, channel_index, 'strides')
    dilations = _get_sequence(dilations, 2, channel_index, 'dilations')
    return gen_nn_ops.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=use_cudnn_on_gpu, explicit_paddings=explicit_paddings, data_format=data_format, dilations=dilations, name=name)