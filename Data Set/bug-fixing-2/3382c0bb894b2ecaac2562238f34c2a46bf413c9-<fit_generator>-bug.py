

@interfaces.legacy_generator_methods_support
def fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0):
    "Fits the model on data generated batch-by-batch by a Python generator.\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        # Arguments\n            generator: A generator.\n                The output of the generator must be either\n                - a tuple (inputs, targets)\n                - a tuple (inputs, targets, sample_weights).\n                All arrays should contain the same number of samples.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `samples_per_epoch`\n                samples have been seen by the model.\n            steps_per_epoch: Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of unique samples of your dataset\n                divided by the batch size.\n            epochs: Integer, total number of iterations on the data.\n            verbose: Verbosity mode, 0, 1, or 2.\n            callbacks: List of callbacks to be called during training.\n            validation_data: This can be either\n                - A generator for the validation data\n                - A tuple (inputs, targets)\n                - A tuple (inputs, targets, sample_weights).\n            validation_steps: Only relevant if `validation_data`\n                is a generator.\n                Number of samples to use from validation generator\n                at the end of every epoch.\n            class_weight: Dictionary mapping class indices to a weight\n                for the class.\n            max_q_size: Maximum size for the generator queue\n            workers: Maximum number of processes to spin up\n            pickle_safe: Ff True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run)\n\n        # Returns\n            A `History` object.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n\n        # Example\n\n        ```python\n            def generate_arrays_from_file(path):\n                while 1:\n                    f = open(path)\n                    for line in f:\n                        # create Numpy arrays of input data\n                        # and labels, from each line in the file\n                        x, y = process_line(line)\n                        yield (x, y)\n                        f.close()\n\n            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                samples_per_epoch=10000, epochs=10)\n        ```\n        "
    if (self.model is None):
        raise RuntimeError('The model needs to be compiled before being used.')
    return self.model.fit_generator(generator, steps_per_epoch, epochs, verbose=verbose, callbacks=callbacks, validation_data=validation_data, validation_steps=validation_steps, class_weight=class_weight, max_q_size=max_q_size, workers=workers, pickle_safe=pickle_safe, initial_epoch=initial_epoch)
